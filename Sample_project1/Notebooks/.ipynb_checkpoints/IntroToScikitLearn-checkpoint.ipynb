{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fb873b-a2c5-4292-a32f-45c552b9b373",
   "metadata": {},
   "source": [
    "## Intro to Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4af98-162c-48da-90e9-d9515c3edde0",
   "metadata": {},
   "source": [
    "What are we going to cover?\n",
    "* An end  to end Scikit learn workflow\n",
    "* Getting the data ready\n",
    "* Choose the right estimator/algorithm for our problem \n",
    "* We will fit the model and make predictions\n",
    "* Evaluating the model\n",
    "* Improve the model\n",
    "* Save and load a trained model\n",
    "* Putting it all together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44beee9-e104-4d34-ab05-03d68f1d94ab",
   "metadata": {},
   "source": [
    "## An end to end Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43da9016-dc3f-408a-8609-b2b4891cb41a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/heart-disease.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Getting data ready\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m heart_disease \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/heart-disease.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m heart_disease\n",
      "File \u001b[1;32m~\\Desktop\\CV_and_projects\\Udemy_ML_and_Data_Science\\Sample_project1\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\CV_and_projects\\Udemy_ML_and_Data_Science\\Sample_project1\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Desktop\\CV_and_projects\\Udemy_ML_and_Data_Science\\Sample_project1\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\CV_and_projects\\Udemy_ML_and_Data_Science\\Sample_project1\\env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\Desktop\\CV_and_projects\\Udemy_ML_and_Data_Science\\Sample_project1\\env\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/heart-disease.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Getting data ready\n",
    "import pandas as pd\n",
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27ea14-3e2d-4423-9218-7b1240791f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=  feature matrix/variables\n",
    "X = heart_disease.drop(\"target\",axis = 1)\n",
    "# y = target variables\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db21065-8d0e-4770-b75a-705f0b17543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the right model and hyperparameters\n",
    "# Example here:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier() #clf =classifier\n",
    "# We will keep the default params (Hyper params)\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3d338-0b64-47ca-9ad8-5a7a0a79b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3065e3-f9f6-4835-a51b-fe4d81fd1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6469c2-1385-47b3-8246-0a602827f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions \n",
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85543be2-beda-4dd7-ad68-8b44e1358cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da761d9d-7812-46be-8fb7-2a664e5faef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d68c1-4b19-4bb2-9265-050030c8b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33614cfc-f703-441c-8d39-33f3cfc4b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ccaa1-db50-4711-9d64-6a89fe8c02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48644f01-cde1-4a82-876c-3e184ccaf993",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a6f3f-8796-4a31-b8fb-da1f67f140fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improve the model\n",
    "# Try different amount of n estimators (a certain hyper parameter)\n",
    "np.random.seed(42)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators= i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(f\" [T] - Model accuracy on test set: {clf.score(X_test,y_test)* 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332257a-e4bd-4fb4-b8b2-9465ffbb0196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE a model and load it\n",
    "import pickle\n",
    "pickle.dump(clf,open(\"../trained_models/random_forest_model_1.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555d37b-e8e7-41d3-ad16-a3b8bf547d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"../trained_models/random_forest_model_1.pkl\",\"rb\"))\n",
    "loaded_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5e130-1b1c-4236-8ca1-bcf3bf6d330d",
   "metadata": {},
   "source": [
    "## 1.Getting our data ready\n",
    "Three main things we have to do:\n",
    "1. Split th data into features and labels (usually 'X','y')\n",
    "2. Filling\\imputing\\disregarding missing values\n",
    "3. Converting non numerical values to numerical (feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b66f3-cc56-494d-8464-3a341f0823a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609edcf-cf72-4c85-bf33-d5f5016bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\",axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039f615-36b4-4549-a2a8-9fd661b62e49",
   "metadata": {},
   "outputs": [],
   "source": [
    " y =heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea43027-d2cf-42c0-919f-9c3a0737e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data to training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6c657-6ebe-4a2d-b305-99796170e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170246a3-300d-477b-a678-4c9475443d34",
   "metadata": {},
   "source": [
    "## 1.1 Make sure everything is numerical (car-sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97923c3f-63ba-4b3e-802d-ef059105970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales  = pd.read_csv(\"data/scikit-learn-data/car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4c777-00a5-4ebe-890f-31ba8c8a87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales),car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b80621-ea17-4b82-9270-8a96b3c9bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X/y\n",
    "X= car_sales.drop(\"Price\",axis = 1)\n",
    "y = car_sales[\"Price\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4c12a-9b2e-4100-be73-36bcf4003e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build machine learning model \n",
    "# prdeict a number -> regressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eeed9c-b777-452e-a210-34ce05a4a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33215f-83c5-44ab-be7f-e4425313e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"] #Doors are treated like buckets,since they are counted \n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                    remainder = \"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13a5b2-17ec-43d5-a95c-1965ef395f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(transformed_X)\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d86eb3-7d4e-4888-940d-1c07812dc90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\",\"Colour\",\"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca2c03-6832-4fda-93e6-b9fcdc6fb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refitting the model\n",
    "np.random.seed(42)\n",
    "X_train,X_test,y_train,y_test = train_test_split(transformed_X,\n",
    "                                                 y,\n",
    "                                                 test_size= 0.2)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ceddd2-9076-4f2d-b85c-9a281c61cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretty bad , need more kinds of info maybe\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945cb10-8778-4112-b6a9-636e811c2c74",
   "metadata": {},
   "source": [
    "## 1.2 Missing values\n",
    "1. Fill them with some value (imputation)\n",
    "2. Remove the samples with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec0473-995b-476a-a15f-46b1fdaf7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"data/scikit-learn-data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head(),len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e580a4-d6c3-4d26-a62b-27b7a104b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e96ed5-ae38-4a01-9a3a-e6df6bdf3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try converting to numbers\n",
    "#Create X/y\n",
    "X = car_sales_missing.drop(\"Price\",axis= 1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "#Conversion\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"] #Doors are treated like buckets,since they are counted \n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                    remainder = \"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4c382-a7c7-482b-bceb-edda7161df28",
   "metadata": {},
   "source": [
    "### option 1  :Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6164dafb-41a5-4ef0-a102-288b84b2a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill \"Make\"\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\",inplace=True)\n",
    "# Fill \"Colour\"\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\",inplace=True)\n",
    "# Fill \"Odometer (KM)\"\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean()\n",
    "                                          ,inplace=True)\n",
    "# Fill \"Doors\"\n",
    "car_sales_missing[\"Doors\"].fillna(4,inplace=True) #Just basic human logic, and this is the majority\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88a249-43c2-4b92-b75d-3b2bf74de91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### option 2: Removal (fitting for missing target values)\n",
    "car_sales_missing.dropna(subset = [\"Price\"],inplace=True)\n",
    "len(car_sales_missing),car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02f6177-f734-4645-b012-5d29c3410263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X/y\n",
    "X = car_sales_missing.drop(\"Price\",axis = 1)\n",
    "y= car_sales_missing[\"Price\"]\n",
    "#Conversion\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"] #Doors are treated like buckets,since they are counted \n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                    remainder = \"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730d2f4-5971-4aec-b636-02d3ec969d54",
   "metadata": {},
   "source": [
    "### 1.2.2 Filling missing values with sklearn (before was pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848cef12-a6be-496f-89f8-b5ca376d8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re reading\n",
    "car_sales_missing = pd.read_csv(\"data/scikit-learn-data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f3736-fcab-4da7-85e6-01fd89b0a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(subset= [\"Price\"],inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96056458-1945-492c-94d2-9b152dd6e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into X/y\n",
    "X = car_sales_missing.drop(\"Price\",axis = 1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c7dd1-4252-4c88-b64d-20636764402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn cleaning/filling\n",
    "from sklearn.impute import SimpleImputer #Filler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#Fill categorical values with \"missing\", and numerical with mean\n",
    "cat_imputer = SimpleImputer(strategy= \"constant\",fill_value=\"missing\")#cat = categorical\n",
    "door_imputer = SimpleImputer(strategy= \"constant\",fill_value= 4) # Same reasoning as before\n",
    "num_imputer = SimpleImputer(strategy= \"mean\")\n",
    "\n",
    "##Define columns\n",
    "cat_features= [\"Make\",\"Colour\"]\n",
    "door_features = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "#Create an imputer to fill the missing the data\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\",cat_imputer,cat_features),\n",
    "    (\"door_imputer\",door_imputer,door_features),\n",
    "    (\"num_imputer\",num_imputer,num_features)\n",
    "])\n",
    "#Transforming the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57454f61-b047-4554-9775-f2ab650575e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(data = filled_X,\n",
    "                               columns=[\"Make\",\"Colours\",\"Doors\",\"Odometer (KM)\"])\n",
    "car_sales_filled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d9cf6-ff7c-485c-9208-c82c66f1068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum(),len(car_sales_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc18c9-c480-4d9d-a1f1-b0814070f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re converting to numbers\n",
    "#Split into X/y\n",
    "X = car_sales_filled #Price already dropped \n",
    "y = car_sales_missing[\"Price\"]\n",
    "#Conversion\n",
    "categorical_features = [\"Make\",\"Colours\",\"Doors\"] #Doors are treated like buckets,since they are counted \n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                    remainder = \"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b6bfb-d79c-4820-9e3a-48c8d54b1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model \n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(transformed_X,\n",
    "                                                 y,\n",
    "                                                test_size= 0.2\n",
    "                                                )\n",
    "model = RandomForestRegressor(n_estimators= 100)\n",
    "model.fit(X_train,y_train)\n",
    "#Scoring\n",
    "model.score(X_test,y_test)\n",
    "#pretty bad Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d669528-df22-4d91-8e60-848b3ec4d465",
   "metadata": {},
   "source": [
    "## 2.Choosing the right estimator\n",
    "- sklearn refers to machine learning models and models as estimators\n",
    "1. For classification problems: predicting a category (heart disease or not)\n",
    "   - Sometimes we can see the 'clf' abbreviation\n",
    "2. For regression problems: predicting a number (selling price of car)\n",
    "\n",
    "Cheat sheet!:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a08bb4-a1ea-45f3-b5fc-fdcfafd6f32d",
   "metadata": {},
   "source": [
    "<img src = \"ml_map.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6894f-da59-419a-9cb3-fd2470baac91",
   "metadata": {},
   "source": [
    "## 2.1 picking a model for a regression problem (california housing dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6fdfc-b22b-490e-a150-925e82f62947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get california housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022f224-45a6-494e-a6c7-daef50de6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning this to a data frame\n",
    "housing_df = pd.DataFrame(data = housing[\"data\"],\n",
    "                         columns= housing[\"feature_names\"],\n",
    "                         )\n",
    "housing_df[\"target\"] = housing[\"target\"] #value normalized to be in $100,000\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5edd1-5c8e-4aa4-9b76-366d38145ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import algorithm (We decided on ridge regression)\n",
    "from sklearn.linear_model import Ridge\n",
    "#Set up random seed,to split the same\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create data\n",
    "X = housing_df.drop(\"target\",axis = 1)\n",
    "y = housing_df[\"target\"] #MedHouseVal\n",
    "\n",
    "#Split the data to train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)\n",
    "\n",
    "# Instantiate and fit the model on the training set\n",
    "model = Ridge()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c1e70-16fe-4daf-a857-037dd1c2120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the model on the test set\n",
    "model.score(X_test,y_test) #coefficient of determination, R^2,Higher is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94ae15-e2b9-49ec-8429-9b5bddd6d058",
   "metadata": {},
   "source": [
    "#Improvements,trying different models maybe\n",
    "- Ensemble models: combining the prediction of several base estimators. To improve generalization\n",
    "- Ensemble RandomForest model: lots of decision trees,and majority Voting/ average for classification and regression respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46382a0d-3723-40cb-ae98-26a3e159f6be",
   "metadata": {},
   "source": [
    "## Trying RandomForestRegressor\n",
    "(Takes alot of time lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20998ef7-5a52-47cf-a28f-ad3b8175438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Import algorithm (We decided on RandomForestRegressor)\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# #Set up random seed,to split the same\n",
    "# np.random.seed(42)\n",
    "\n",
    "# #Create data\n",
    "# X = housing_df.drop(\"target\",axis = 1)\n",
    "# y = housing_df[\"target\"] #MedHouseVal\n",
    "\n",
    "# #Split the data to train and test\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)\n",
    "\n",
    "# # Instantiate and fit the model on the training set\n",
    "# model = RandomForestRegressor(n_estimators= 100)\n",
    "# model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1286ee6-6914-4493-bce3-efa34270ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Score the model on the test set (Need to research more metrics)\n",
    "# model.score(X_test,y_test) #coefficient of determination, R^2,Higher is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ead066-923f-41e7-9146-c86832bc661d",
   "metadata": {},
   "source": [
    "## 2.2 picking a model for a classification problem (heart disease dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabf3cc-4d67-4191-a2fd-c4b17707d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4175a6-44c0-4918-aa46-d537056a6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a3cca-0288-4cee-9c04-13e5f5f48bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import algorithm (We decided on LinearSvc)\n",
    "from sklearn.svm import LinearSVC\n",
    "#Set up random seed,to split the same\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create data\n",
    "X = heart_disease.drop(\"target\",axis = 1)\n",
    "y = heart_disease[\"target\"] #MedHouseVal\n",
    "\n",
    "#Split the data to train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)\n",
    "\n",
    "# Instantiate and fit the model on the training set\n",
    "clf = LinearSVC(dual= True,max_iter=1000)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c59c6-a381-48fe-94df-28f6d7b446a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score\n",
    "clf.score(X_test,y_test) # The lecture got 47% accuracy, don't know why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efdbd76-458e-428d-a8f3-cd8be0223f91",
   "metadata": {},
   "source": [
    " - Trying the classifier instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55654e63-0180-4629-b12d-de1c7a49bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import algorithm (We decided on Random forest classifier)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Set up random seed,to split the same\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create data\n",
    "X = heart_disease.drop(\"target\",axis = 1)\n",
    "y = heart_disease[\"target\"] #MedHouseVal\n",
    "\n",
    "#Split the data to train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)\n",
    "\n",
    "# Instantiate and fit the model on the training set\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9372ae2-d1aa-4c48-9e20-5e63719a9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score\n",
    "clf.score(X_test,y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebb6c3-cc2c-4bc9-b788-aec57dcaad83",
   "metadata": {},
   "source": [
    "## Tidbit: (General guide line)\n",
    "1. if we have structured data ,we should use ensemble methods (things in a data frame)\n",
    "2. if we have structured data ,we should use deep learning or transfer learning (audio, text, images... )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb5b6a-d852-4cdc-889f-b41007d5e8d9",
   "metadata": {},
   "source": [
    "## 3. Fitting the model and use it to make predictions\n",
    "### 3.1 Fitting the data\n",
    "Different names for:\n",
    "- `x` = features , feature variables, data\n",
    "- `y` = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9aa41b-b361-407d-a6ac-01c06ab23f04",
   "metadata": {},
   "source": [
    "### 3.2 Making predictions with our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87987b3-216a-4031-aef7-2c15a67a50e0",
   "metadata": {},
   "source": [
    "### Training the classifier for heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4d5b8-2203-4b20-99c1-f04510adfa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import algorithm (We decided on Random forest classifier)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Set up random seed,to split the same\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create data\n",
    "X = heart_disease.drop(\"target\",axis = 1)\n",
    "y = heart_disease[\"target\"] #MedHouseVal\n",
    "\n",
    "#Split the data to train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)\n",
    "\n",
    "# Instantiate and fit the model on the training set\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "#Fitting the model to the data\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d6348-eeff-4e75-b7a7-63ba7984fc40",
   "metadata": {},
   "source": [
    "### 3.2 Making predictins with the model\n",
    "2 main ways to make predictions:\n",
    "  1. `predict()`\n",
    "  2.  `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d92ee3-4e20-4384-92a7-f2b2774687df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd56b38-6981-4be2-9219-31f2276c0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test) #predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3f0b1-240c-49f9-8e09-ef1111bad3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test) #truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6a0b2-deec-4dda-93c5-ff922513dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ca813-dbb7-4ef1-bcd8-c3a35d57ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring using mean\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6e22a-bc2c-49c7-a20a-c7d8b155a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb90d32-d9e1-40ce-a536-650400e1713b",
   "metadata": {},
   "source": [
    "## `predict_proba()`\n",
    "returns probability estimates of a classification label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb065a-ab87-45f4-81c2-15e10b4f0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05471913-3f6a-4093-89a4-eb8a2782953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets predict() on the same data \n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc19674-117f-491a-bc17-d69bf8e073d3",
   "metadata": {},
   "source": [
    "`predict()` can also be used with regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cec547-0797-4463-885b-ee7f61f11f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bfcaa-b9cb-4c93-8fef-2cc1528b0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "#Create data\n",
    "X = housing_df.drop(\"target\",axis= 1)\n",
    "y= housing_df[\"target\"]\n",
    "# split to train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "#Create model instance\n",
    "model = RandomForestRegressor(n_estimators= 100)\n",
    "#Fit model\n",
    "model.fit(X_train,y_train)\n",
    "#Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f439beb-9485-4f90-8592-740d9d9a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48911382-09e1-47a8-ae56-be8e24a9b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a70284-e3e1-461a-86f6-2c29384dc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test),len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1710cab-fef2-46ec-99f4-55705b12319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating according to mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10b6ab-72c9-431d-a3d3-dfb56e4cd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"target\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e493a5-14e0-44df-b795-c964bfa7a2e2",
   "metadata": {},
   "source": [
    "## 4. Evaluating our models\n",
    "Three ways to evaluate Sklearn models:\n",
    "1. Estimators built in `score()` function\n",
    "2. The `scoring` parameter\n",
    "3. Problem - specific metric functions (sklearn.metrics)\n",
    "\n",
    "More info at : https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d88a1-08a3-44d7-a271-757c777a2a34",
   "metadata": {},
   "source": [
    "### 4.1 The score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462cb3fa-0f09-42e9-a273-d4b0dbae0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "#Create data\n",
    "X = heart_disease.drop(\"target\",axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "#Split train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "#Create classifier instance\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "#Fit model\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86ed4b-f99c-4557-adc3-7cf47d841ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make preditions with score\n",
    "clf.score(X_train,y_train)# On training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d821a6-57ea-4e5a-a90b-ab5aaef2156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make preditions with score\n",
    "clf.score(X_test,y_test)# On train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d218116-65cd-4cef-ae5e-bce7664af2e2",
   "metadata": {},
   "source": [
    "Lets use the `score()` on our regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39997da-a961-4313-a9d4-9770d847290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "#Create data\n",
    "X = housing_df.drop(\"target\",axis = 1)\n",
    "y = housing_df[\"target\"]\n",
    "#Split train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "#Create model instance\n",
    "model = RandomForestRegressor(n_estimators=2)\n",
    "#Fitting model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe2513-21fd-4068-a080-9a145eb02a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)#n_estimators = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f4c3b-e3f5-4e7a-b76f-d31774d5eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=10)\n",
    "#Fitting model\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)#n_estimators = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f689a4-3f8d-4714-a245-510b28bac083",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=20)\n",
    "#Fitting model\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)#n_estimators = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1d4f2-173b-4b4f-95c6-9640f7815db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50)\n",
    "#Fitting model\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)#n_estimators = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabccfaf-aa51-461f-bb9a-345ddac17834",
   "metadata": {},
   "source": [
    "## 4.2 `Scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe3ee44-e1cc-4201-ab14-0ed3a6081495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "#Create data\n",
    "X = heart_disease.drop(\"target\",axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "#Split train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "#Create classifier instance\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "#Fit model\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fcd98-a572-42c0-9b35-8aa3a4cc1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123fab71-56fd-4907-85a1-ff44f4e3be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf,X,y,cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329adedb-37cb-45e5-950e-24b9c7341afd",
   "metadata": {},
   "source": [
    "<img src = \"Cross-validation-chart.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793c3eb-ca5a-4b50-b6f0-88b0685b36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cross_validation_array = cross_val_score(clf,X,y,cv = 5) #Five fold\n",
    "np.mean(cross_validation_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c0395-801b-485b-a450-aa3cc695cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cross_validation_array = cross_val_score(clf,X,y,cv = 10) #Ten fold\n",
    "np.mean(cross_validation_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5b5b8-1460-481f-909e-19149b78dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cross_validation_array = cross_val_score(clf,X,y,cv = 20) #20 fold\n",
    "np.mean(cross_validation_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e85433-3880-452a-b976-c187ca19c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring parameter set to none by default\n",
    "cross_validation_array = cross_val_score(clf,X,y,cv = 5,scoring= None)\n",
    "#None == default scoring param of estimator if one exists, this case is mean accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc759366-90e3-4889-b03c-f32158609d3f",
   "metadata": {},
   "source": [
    "### We can import our own scoring parameter!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a539a-b0b7-47ed-850c-50141cb56d2f",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd96820-7daa-465f-b811-a707df458d63",
   "metadata": {},
   "source": [
    "### 4.2.1.1 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b76c3-5a24-43ce-b4e1-9e7c483e9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\",axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "cross_validation_array = cross_val_score(clf,X,y,cv = 5,scoring= None)\n",
    "np.mean(cross_validation_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe7acf-e609-459d-aa91-c36285a9c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart disease classifier Cross validation score: {np.mean(cross_validation_array) *100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352cf6f-4289-49da-b0ba-24bcdf79cf61",
   "metadata": {},
   "source": [
    "### 4.2.1.2 Area under Reciever Operating characteristic curve (AUC/ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52504caf-e463-4f0c-99b8-90ff796b83b3",
   "metadata": {},
   "source": [
    "ROC curves are a comparison of a model's true positive rate (tpr) versus a models false positive rate (fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa4be1-1613-40db-9369-e98c2a22e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\",axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "#Split train and test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "#Classifier instance\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Fit model\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "y_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75167710-3975-4755-83b3-150f36a3d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split probs to positive and negative\n",
    "y_probs_positive = y_probs[:,1]\n",
    "y_probs_negative = y_probs[:,0]\n",
    "y_probs_positive[:10],y_probs_negative[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17800569-889f-479d-877c-bd9edd49ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr,thresholds = roc_curve(y_test,y_probs_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8dcaec-9988-4d03-9cde-5aeaf86bb185",
   "metadata": {},
   "source": [
    "## Create a function for plotting ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8681c-6cec-4571-863d-5e0349efe57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ab098-a29b-4a51-aa5a-e12a383016d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr,tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model\n",
    "    \"\"\"\n",
    "    #Plot roc curve\n",
    "    plt.plot(fpr,tpr,color = \"orange\", label = \"ROC\")\n",
    "    #PLot with no predictive power (baseline)\n",
    "    plt.plot([0,1],[0,1],color = \"darkblue\",linestyle = \"--\",label = \"Guessing\")\n",
    "    #Customize plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"true positive rate (tpr)\")\n",
    "    plt.title(\"Reciever Operating Characteristics (ROC) Curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da9ae1-ece0-40fe-a2d6-6700726bed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr,thresholds = roc_curve(y_test,y_probs_positive)\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08293c9-769d-4d96-b8fb-2042c9d0a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area under curve scoring\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946bb27-daa6-4004-bd62-9b5e58b531ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting perfect ROC curve and AUC \n",
    "fpr, tpr,thresholds = roc_curve(y_test,y_test)\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeefe43-bdff-48f8-87db-a793c3869940",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd666f-9cef-4f20-bca5-17bd9a9617cf",
   "metadata": {},
   "source": [
    "### 4.2.1.3 Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839e5ad-6746-4879-94ae-65dbeebe6cd8",
   "metadata": {},
   "source": [
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual\n",
    "labels it was supposed to predict.\n",
    "In essence giving us an idea of where the model got confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d01ec1-c276-4311-a2d3-b748e881a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_preds = clf.predict(X_test)\n",
    "confusion_matrix(y_true= y_test,y_pred = y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230e041-8830-4407-9679-e617f5c50358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize confusion matric with pd.crosstab()\n",
    "pd.crosstab(y_test,y_preds,\n",
    "           rownames=[\"Actual labels\"],\n",
    "           colnames=[\"Predicted labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715aa9d-622e-4494-b163-cb07e892a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a seaborn heatmap() with our confusion matrix\n",
    "import seaborn as sns\n",
    "#Set the font scale\n",
    "sns.set(font_scale= 1.5)\n",
    "#create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_true =y_test,y_pred=y_preds)\n",
    "#Plot confusion\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690324e-4125-4981-bb97-de136e2acdc7",
   "metadata": {},
   "source": [
    "## Nothing to see up here really, need more numbers and stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf957f3-1f90-44cc-be8a-720ae9436eed",
   "metadata": {},
   "source": [
    "### Basic customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52846919-3dc6-4994-b4c2-8a6c9ce0589a",
   "metadata": {},
   "source": [
    "1. Make predictions amd produce confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2d7e5-0302-4064-aafc-d518d7e8658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_preds = clf.predict(X_test)\n",
    "confusion_matrix(y_true= y_test,y_pred = y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f9440-6560-4490-b1da-c53ed1888279",
   "metadata": {},
   "source": [
    "2. Viewing pandas crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c1fb6-2eb8-423d-94c3-201545c61f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test,y_preds,\n",
    "           rownames=[\"Actual Label\"],\n",
    "           colnames=[\"Predicted label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66bbdb3-68c9-42b0-82e2-b6f3ca761751",
   "metadata": {},
   "source": [
    "3. Let us plot this matrix, we want a colorful bright diagonal\n",
    "   Using  `Sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6c937-988c-4d10-a1eb-483ca2ea30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf,X=X,y=y)# makes predictions for me On the ENTIRE data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad2d86-4762-48aa-9320-851f581ca513",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test,\n",
    "                                       y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848374d-ecc6-4808-aa1c-2c3bd45a258f",
   "metadata": {},
   "source": [
    "### 4.2.1.4 Classification report (Multiple metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad1b10-e264-45c0-984e-90249ae0c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd657e4-07fd-4376-ae00-9e560251cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 #Only one positive case\n",
    "disease_preds = np.zeros(10000)#Model predicts everything to be zero\n",
    "\n",
    "pd.DataFrame(classification_report(y_true=disease_true,y_pred=disease_preds,output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a9ed23-e8d8-4f0b-9d2f-2131207567fe",
   "metadata": {},
   "source": [
    "## 4.2.2 Evaluating a Regression model\n",
    "* Search \"Regression metrics\" in sklearn\n",
    "\n",
    "- The ones we are going to cover:\n",
    "  1. R^2\n",
    "  2. Mean absolute error (MAE)\n",
    "  3. Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c1feb-e656-4be3-9c60-65e914973d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "#Create data\n",
    "X = housing_df.drop(\"target\",axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "#split data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "#instancing model\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "#fitting model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cdc876-bc98-4bc2-b46b-e490f1065eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)#coefficient of determination (can be negative!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f9a5c-fea6-4dbb-955a-016327b17f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE a california housing model\n",
    "import pickle\n",
    "pickle.dump(model,open(\"models/cali_housing_random_forest_model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dadebb-7ed8-46b9-9fd8-aef1c1a83c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"models/cali_housing_random_forest_model.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a36055-487f-47b7-9cd5-e9217274cf2c",
   "metadata": {},
   "source": [
    "## 4.2.2.1 R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7487d1-c288-4996-bb98-edb7b71c2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "#Fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test),y_test.mean())\n",
    "y_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299db33-6915-4162-8f07-1b7fee67345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true= y_test,\n",
    "        y_pred= y_test_mean) #Assuming the model predicted just the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d522d1-7da5-4daa-8115-cf5400f348e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual trained model score\n",
    "y_preds = model.predict(X_test)\n",
    "r2_score(y_true= y_test,\n",
    "        y_pred= y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf078db-03d6-4bbb-b04e-e683c448d661",
   "metadata": {},
   "source": [
    "## 4.2.2.2 Mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50102198-cd29-4628-bae1-c83f6e33b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "y_preds = model.predict(X_test)\n",
    "mae(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f617f-f3a7-4f31-905b-d19ab6c17fa8",
   "metadata": {},
   "source": [
    "^---- how far away is ourmodel from the \"truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e84661-98fe-4804-b035-6346fe56c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Actual values\": y_test,\n",
    "                       \"Predicted values\": y_preds})\n",
    "df[\"Differences\"] =df[\"Predicted values\"]- df[\"Actual values\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16acb98-c7ed-41fb-827b-2c5bde15a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Differences (Absolute)\"] = np.abs(df[\"Differences\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a19105-0e45-4a9a-acab-d40927d3b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Differences\"].mean() ,df[\"Differences (Absolute)\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8a853-1929-4e84-b5b4-c024f05d8707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
